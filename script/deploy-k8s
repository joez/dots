#!/usr/bin/env bash
# author: joe.zheng
# version: 23.04.14

set -e

SELF=`basename $0`

SUDO="sudo"
if [[ $(id -u) == "0" ]]; then
  SUDO=""
fi

DOCKER="$SUDO docker"
if id -nG | grep -qw docker; then
  DOCKER="docker"
fi

# IP of the primary interface on the host
HOST_IP=$(ip route get 1 | head -1 | awk '{print $7}')
HOST_DNS=$(perl -e 'use Net::Domain hostfqdn; print hostfqdn')
HOST_NAME=$(perl -e 'use Net::Domain hostname; print hostname')

K8S_NOPROXY=".svc,.svc.cluster.local"
K8S_PKGS="kubelet kubeadm kubectl"
CACHE="cache"                         # the cache directory
CACHE_IMAGE="$CACHE/image"            # script to save or load images
INIT_CONFIG="kubeadm-init.yaml"       # config file for "kubeadm init"
JOIN_MANUAL="kubeadm-join.txt"        # "kubeadm join" instructions

ADDRESS=$HOST_IP      # API server IP address
PORT=6443             # API server IP port
BACKEND="vxlan"       # flannel backend
BACKENDS="none vxlan wireguard" # valid flannel backend options
ENDPOINT=""           # endpoint for all control-plane nodes
SANS=$HOST_DNS        # API server certificate SANs
NODE=""               # specify node name
VERSION=1.23.0        # k8s stable version
MIRROR=auto           # mirror option
MIRRORS="yes no auto" # valid mirror options
RESET=n               # reset cluster first
DRY_RUN=n             # dry run or not
OFFLINE=${OFFLINE:-n} # no external network
NO_CLUSTER=n          # do not init cluster
NO_WORKLOAD=n         # do not schedule workload on control-plane node

CRI_DOCKERD_VER=0.2.6                              # cri-dockerd version
CRI_DOCKERD_SOC="unix:///var/run/cri-dockerd.sock" # cri-dockerd socket path

function msg() {
  echo "> $@"
}

function err() {
  echo "> $@" >&2
}

function realfile() {
  [[ -L "$1" ]] && readlink -f $1 || echo $1
}

function usage() {
  cat <<EOF
Usage: $SELF [-a <addr>] [-b <type>] [-e <addr>] [-s <sans>] [-m <type>]
  [-N <name>] [-v <ver>] [-r] [-R] [-C] [-W] [-n] [-h]

  Deploy Kubernetes and initialize a cluster the easy way

  -a <addr>: API server IP address, default: $ADDRESS
  -b <type>: Flannel backend [$BACKENDS], default: $BACKEND
  -e <addr>: endpoint for all control-plane nodes, default: "$ENDPOINT"
  -s <sans>: API server certificate SANs separated by ",", default: $SANS
  -m <type>: mirror option [$MIRRORS], default: $MIRROR
  -N <name>: set node name, instead of the actual hostname, default: "$NODE"
  -v <ver>:  k8s version, default: $VERSION
  -r:        reset k8s cluster first, default: $RESET
  -R:        reset k8s cluster and stop, same as -rC
  -C:        do not initialize cluster, default: $NO_CLUSTER
  -W:        do not schedule workload on control-plane node, default: $NO_WORKLOAD
  -n:        dry run, print out information only, default: $DRY_RUN
  -h:        print the usage message

Offline mode:

  To support deployment in offline mode, the required packages and containers
  will be cached in the folder "$CACHE/" when deploying it on a machine with
  internet connection, then copy the cache to the target machine and deploy it

  You can save all the downloaded container images by this command:

    $CACHE_IMAGE

  These cached files will be loaded in offline mode when necessary:

  * The software packages in "$CACHE/packages"
  * The container images in "$CACHE/images"

  The offline mode will be enabled automatically through network detection.
  You can also force it by setting environment variable "OFFLINE=y"

Examples:

  1. Deploy a single node cluster
     $SELF

  2. Reset the cluster and deploy again
     $SELF -r

  3. Reset the cluster and deploy again with specific version
     $SELF -r -v 1.21.0

  4. Deploy a cluster with one control-plane and one worker node
     # on control-plane node
     $SELF -W
     # check the output command for "kubeadm join"

     # on worker node
     $SELF -C
     # use "kubeadm join" command to join the cluster

  5. Deploy a control-plane node with DNS name vip.k8s.io
     $SELF -W -e vip.k8s.io
EOF

}

while getopts ":a:b:e:s:m:N:v:hCWnRr" opt
do
  case $opt in
    a ) ADDRESS=$OPTARG;;
    b ) BACKEND=$OPTARG
        if echo $BACKENDS | grep -v -w $BACKEND >/dev/null 2>&1; then
          echo "invalid backend option $BACKEND"
          usage && exit 1
        fi
        ;;
    e ) ENDPOINT=$OPTARG;;
    s ) SANS=$OPTARG;;
    m ) MIRROR=$OPTARG
        if echo $MIRRORS | grep -v -w $MIRROR >/dev/null 2>&1; then
          echo "invalid mirror option $MIRROR"
          usage && exit 1
        fi
        ;;
    N ) NODE=$OPTARG;;
    v ) VERSION=${OPTARG#v};;
    r ) RESET=y;;
    R ) RESET=y && NO_CLUSTER=y;;
    n ) DRY_RUN=y;;
    C ) NO_CLUSTER=y;;
    W ) NO_WORKLOAD=y;;
    h ) usage && exit;;
    * ) usage && echo "invalid option: -$OPTARG" && exit 1;;
  esac
done
shift $((OPTIND-1))

for v in DOCKER HOST_IP ADDRESS BACKEND ENDPOINT NODE SANS VERSION MIRROR RESET NO_CLUSTER NO_WORKLOAD DRY_RUN
do
  eval echo "$v: \${$v}"
done

[[ $DRY_RUN == "y" ]] && exit

function main() {
  warn_as_root
  validate_sudo
  check_prerequisites
  ensure_workdir
  ensure_swapoff
  ensure_iptables
  ensure_selinuxoff
  ensure_firewalloff
  need_mirror
  ensure_installed
  if [[ $RESET == "y" ]]; then
    reset_cluster
  fi
  [[ $NO_CLUSTER != "y" ]] && init_cluster

  msg "done"
  cat <<EOF
here are some useful commands:
- check status: kubectl get pods -A
- enable bash completion: source <(kubectl completion bash)
EOF
}

function dist_name() {
  dist="$(cat /etc/*-release | sed -ne 's/^ID=//p' | xargs echo)"
  if [[ -z $dist ]]; then
    dist="$(lsb_release -s -i)"
  fi
  dist="$(echo $dist | tr '[:upper:]' '[:lower:]')"
  echo $dist
}

function check_prerequisites() {
  msg "check prerequisites"
  if [[ -z $(which perl) ]]; then
    err "perl is not available"
    exit 1
  fi
  if [[ -z $(which curl) ]]; then
    err "curl is not available"
    exit 1
  fi
  if [[ -z $(which openssl) ]]; then
    err "openssl is not available"
    exit 1
  fi
  if [[ -z $(which docker) ]]; then
    err "docker is not available"
    exit 1
  fi
  msg "check network"
  if ! curl -s -m 3 ifconfig.co >/dev/null; then
    err "can't access external network, continue for offline scenario"
    OFFLINE="y"
  else
    msg "check docker pull"
    if ! $DOCKER pull hello-world >/dev/null 2>&1; then
      err "docker pull can't work, check docker configuration first"
      exit 1
    fi
  fi
}

NEED_CRI_DOCKERD=n
function need_cri_dockerd() {
  msg "is cri-dockerd needed"

  local target="1.24.0" # the version with dockershim removed
  local smaller="$(printf "%s\n" $target $VERSION | sort -V | head -n1)"
  if [[ $smaller == $target ]]; then
    msg "the requested version $VERSION is greater than $target"
    NEED_CRI_DOCKERD=y
  fi
  msg "need cri-dockerd: $NEED_CRI_DOCKERD"
}

function install_cri_dockerd_if_needed() {
  msg "install cri-dockerd if needed"

  need_cri_dockerd

  if [[ $NEED_CRI_DOCKERD == "y" ]]; then
    if systemctl is-active cri-docker.socket >/dev/null; then
      v="$(cri-dockerd --version 2>&1 | awk '{print $2}')"
      msg "cri-dockerd already installed, version: $v"
      return
    fi

    local ver=$CRI_DOCKERD_VER
    local url="https://github.com/Mirantis/cri-dockerd"
    local dir="$CACHE/packages/common/cri-dockerd"

    mkdir -p $dir

    if [[ $OFFLINE == "y" ]]; then
      msg "WARNING: offline mode, cache must be ready"
      msg "try to install from the cache"
    else
      msg "download into $dir"
      curl -sL ${url}/releases/download/v${ver}/cri-dockerd-${ver}.amd64.tgz | tar xz -C $dir --strip-components=1
      for f in cri-docker.{service,socket}; do
        curl -sL $url/raw/v${ver}/packaging/systemd/$f > $dir/$f
      done
    fi

    msg "now install it"
    $SUDO cp $dir/cri-dockerd /usr/bin/
    $SUDO cp $dir/cri-docker.{service,socket} /etc/systemd/system/
    $SUDO systemctl daemon-reload
    $SUDO systemctl enable cri-docker.service
    $SUDO systemctl enable --now cri-docker.socket
  fi
}

NEED_MIRROR=n
function need_mirror() {
  msg "is mirror needed"
  if [[ $MIRROR == "auto" ]]; then
    MIRROR=yes # default as needed
    msg "check whether we can access google cloud"
    if [[ $OFFLINE == "y" ]]; then
      msg "offline mode, assume mirror is needed"
    else
      local target="k8s.gcr.io/pause"
      if $DOCKER pull $target >/dev/null 2>&1; then
        msg "$DOCKER pull $target is OK"
        target="https://cloud.google.com"
        if curl -s -m 5 $target >/dev/null 2>&1; then
          msg "curl $target is OK"
          MIRROR=no
        else
          msg "curl $target is FAILED"
        fi
      else
        msg "$DOCKER pull $target is FAILED"
      fi
    fi
  fi
  if [[ $MIRROR == "yes" ]]; then
    NEED_MIRROR=y
  fi
  msg "need mirror: $NEED_MIRROR"
}

function install_k8s() {
  local dist=$(dist_name)
  msg "install k8s on \"$dist\""

  local cachedir="$CACHE/packages/$dist"
  mkdir -p $cachedir

  if [[ $OFFLINE == "y" ]]; then
    msg "WARNING: offline mode, cache must be ready"
    msg "try to install package from the cache"
    if [[ $dist == "ubuntu" ]]; then
      msg "install $cachedir/*.deb"
      $SUDO dpkg -i $cachedir/*.deb
      msg "no auto update for $K8S_PKGS"
      $SUDO apt-mark hold $K8S_PKGS
    elif [[ $dist == "centos" || $dist == "openeuler" ]]; then
      msg "install $cachedir/*.rpm"
      $SUDO yum install -y -C --disablerepo=* $cachedir/*.rpm
      msg "enabled and start kubelet"
      $SUDO systemctl enable --now kubelet
    else
      err "dist \"$dist\" is not supported!"
      exit 1
    fi

    if [[ -z $(which kubeadm) ]]; then
      msg "kubeadm is not available"
      exit 1
    fi

    # offline mode is done
    return
  fi

  if [[ $dist == "ubuntu" ]]; then
    local codename="xenial"  # the official doc use xenial for all
    local list="/etc/apt/sources.list.d/kubernetes.list"
    local key="https://packages.cloud.google.com/apt/doc/apt-key.gpg"
    local src="https://apt.kubernetes.io/"
    if [[ $NEED_MIRROR == "y" ]]; then
      key="https://mirrors.aliyun.com/kubernetes/apt/doc/apt-key.gpg"
      src="https://mirrors.aliyun.com/kubernetes/apt/"
    fi

    msg "add key from $key"
    curl -s $key | $SUDO apt-key add -
    msg "add $src to $list for $codename"
    cat <<EOF | $SUDO tee $list
deb $src kubernetes-$codename main
EOF

    msg "clean apt cache before installation"
    $SUDO apt clean

    local pkgsss="$K8S_PKGS "
    local wanted="${pkgsss// /=$VERSION-00 }"
    msg "apt update and install: $wanted"
    # use apt-get instead of apt to keep the downloaded packages
    $SUDO apt update && $SUDO apt-get install -y $wanted
    msg "no auto update for $K8S_PKGS"
    $SUDO apt-mark hold $K8S_PKGS

    msg "save the installed packages to $cachedir"
    cp -r /var/cache/apt/archives/*.deb $cachedir
  elif [[ $dist == "centos" || $dist == "openeuler" ]]; then
    local name="el7-$(uname -m)"
    local list="/etc/yum.repos.d/kubernetes.repo"
    local src="https://packages.cloud.google.com/yum/repos"
    local key="https://packages.cloud.google.com/yum/doc"
    if [[ $NEED_MIRROR == "y" ]]; then
      key="http://mirrors.aliyun.com/kubernetes/yum/doc"
      src="http://mirrors.aliyun.com/kubernetes/yum/repos"
    fi

    msg "add $src to $list for $name"
    # repo_gpgcheck is disabled for centos7
    # details in https://github.com/kubernetes/kubernetes/issues/100757
cat <<EOF | $SUDO tee $list
[kubernetes]
name=Kubernetes
baseurl=$src/kubernetes-$name
enabled=1
gpgcheck=1
repo_gpgcheck=0
gpgkey=$key/yum-key.gpg $key/rpm-package-key.gpg
exclude=kubelet kubeadm kubectl
EOF

    msg "enable yum cache"
    local conf="$(realfile /etc/yum.conf)"
    if grep "keepcache" $conf >/dev/null; then
      $SUDO perl -pi -e 's/(keepcache\s*=\s*).*$/${1}1/' $conf
    else
      $SUDO perl -pi -e 's/^(\s*\[main\].*)$/${1}\nkeepcache=1/' $conf
    fi
    $SUDO yum makecache

    msg "clean yum cache before installation"
    $SUDO yum clean packages

    local pkgsss="$K8S_PKGS "
    local wanted="${pkgsss// /-$VERSION }"
    msg "install $wanted"
    $SUDO yum install -y $wanted --disableexcludes=kubernetes
    msg "enabled and start kubelet"
    $SUDO systemctl enable --now kubelet

    # openEuler use containernetworking-plugins instead of kubernetes-cni
    if [[ $dist == "openeuler" ]] && [[ -d "/usr/libexec/cni" ]]; then
      msg "setup cni for $dist"
      $SUDO mkdir -p /opt/cni/bin && $SUDO ln -sf -t $_ /usr/libexec/cni/*
    fi

    msg "save the installed packages to $cachedir"
    if [[ -d /var/cache/dnf ]]; then
      cp /var/cache/dnf/*/packages/*.rpm $cachedir
    else
      cp /var/cache/yum/*/*/*/packages/*.rpm $cachedir
    fi
  else
    err "dist \"$dist\" is not supported!"
    exit 1
  fi
}

function ensure_selinuxoff() {
  msg "ensure SELinux is off"
  if [[ -n "$(which getenforce)" && "$(getenforce)" == "Enforcing" ]]; then
    msg "set SELinux in permissive mode (effectively disabling it)"
    $SUDO setenforce 0
    $SUDO sed -i 's/^SELINUX=enforcing$/SELINUX=permissive/' /etc/selinux/config
  fi
}

function ensure_installed() {
  msg "ensure k8s installed"

  if [[ -n $(which kubeadm) ]]; then
    local ver="$(kubeadm version -o short)"
    ver=${ver#v}
    msg "already installed, version: $ver"
    if [[ $VERSION != $ver ]]; then
      msg "the requested version ($VERSION) is different from the installed one"
      msg "we only support to switch control-plane version"
      msg "do it by yourself if you really want to switch k8s version"
      msg "here is one solution: reset cluster and delete k8s, then deploy it again"
      local dist=$(dist_name)
      local cmd='apt autoremove'
      if [[ $dist == "centos" || $dist == "openeuler" ]]; then
        cmd='yum remove'
      fi
      msg "  $SELF -R && $SUDO $cmd $K8S_PKGS"
    fi
  else
    install_k8s
  fi

  install_cri_dockerd_if_needed
}

function ensure_swapoff() {
  # k8s requires swapoff
  msg "ensure swap is off"
  local n=`cat /proc/swaps | wc -l`
  if (( n > 1 )); then
    local swap=$(systemctl list-units | perl -ne 'print $1 if /^\s+(dev-\w+\.swap)\s+/')
    if [[ -n $swap ]]
    then
      msg "disable swap device $swap"
      $SUDO systemctl mask $swap
    fi
    msg "disable any swap device in fstab"
    $SUDO perl -pi -e 's/^(.+(none|swap)\s+swap.+)/#$1/ unless /^#/' $(realfile /etc/fstab)
    msg "swapoff -a"
    $SUDO swapoff -a
  else
    msg "no swap device"
  fi
}

function ensure_firewalloff() {
  msg "ensure firewall is off for simplicity"
  if [[ "$(systemctl is-active firewalld)" == "active" ]]; then
    echo "firewall is active, stop and disable it"
    $SUDO systemctl stop firewalld
    $SUDO systemctl disable firewalld
  fi
}

function ensure_iptables() {
  msg "ensure iptables see bridged traffic"
  if ! lsmod | grep -wq br_netfilter; then
    echo "br_netfilter is not loaded, load it and make it auto-loaded"
    $SUDO modprobe br_netfilter
    cat <<EOF | $SUDO tee /etc/modules-load.d/k8s.conf
br_netfilter
EOF
  fi
  local prefix="/proc/sys/net/bridge/bridge-nf-call-ip"
  if [[ "$(cat ${prefix}tables)" != "1" || "$(cat ${prefix}6tables)" != "1" ]]; then
    msg "bridge-nf-call-iptables is disabled, enable it"
    cat <<EOF | $SUDO tee /etc/sysctl.d/k8s.conf
net.bridge.bridge-nf-call-ip6tables = 1
net.bridge.bridge-nf-call-iptables = 1
EOF
    $SUDO sysctl --system
  fi
}

function warn_as_root() {
  if [[ $(id -u) == "0" ]]; then
    msg "you are running as root user, kubectl will be configured to root only!"
    sleep 3
  fi
}

function validate_sudo() {
  if [[ -n $SUDO ]]; then
    msg "validate sudo"
    sudo -v
  fi
}

function ensure_workdir() {
  msg "ensure workdir"

  if [[ ! -d $CACHE ]]; then
    msg "create dir: $CACHE"
    mkdir -p $CACHE
  fi

  if [[ ! -f $CACHE_IMAGE ]]; then
    msg "create script: $CACHE_IMAGE"
cat <<'EOF' > $CACHE_IMAGE
#!/usr/bin/env bash
# AUTO-GENERATED
# load or save images

set -e

DOCKER="sudo docker"
if [[ "$(id -u)" == "0" ]] || id -nG | grep -qw docker; then
  DOCKER="docker"
fi

mkdir -p $(dirname $0)/images && cd $_

if [[ $1 == "load" ]]; then
  echo "load images:"
  images="$(find . -type f -name '*tar.gz')"
  for i in $images; do
    file="${i#./}"
    echo "loading $file"
    if [[ $DRY_RUN != 'y' ]]; then
      $DOCKER load -i $file
    fi
  done
else
  echo "save images:"
  images="$($DOCKER images -f 'dangling=false' --format '{{.Repository}}:{{.Tag}}')"
  for i in $images; do
    if [[ -n "$RE_IGNORE" && $i =~ $RE_IGNORE ]]; then
      echo "ignore $i" && continue
    fi
    file="${i//:/-}.tar.gz"
    echo "saving $i"
    echo "    -> $file"
    if [[ $DRY_RUN != 'y' ]]; then
      mkdir -p $(dirname $i) && $DOCKER save $i | gzip > $file;
    fi
  done
fi
echo "done"
EOF

    chmod a+x $CACHE_IMAGE
  fi
}

function reset_cluster() {
  msg "reset cluster"
  local params=
  if [[ $NEED_CRI_DOCKERD == "y" ]]; then
    params="$params --cri-socket $CRI_DOCKERD_SOC"
    msg "set cri-socket as $CRI_DOCKERD_SOC"
  fi
  $SUDO kubeadm reset $params

  msg "release cni0 if any"
  if ip link show cni0 >/dev/null 2>&1; then
    $SUDO ip link set cni0 down
    $SUDO ip link delete cni0
  fi
  msg "clean cni config"
  $SUDO rm -rf /etc/cni/net.d/
}

function init_cluster() {
  msg "initialize cluster"

  if kubectl cluster-info >/dev/null 2>&1; then
    msg "already initialized"
    return
  fi

  [[ $OFFLINE == "y" ]] && msg "WARNING: offline mode, cache must be ready"

  local flannel="$CACHE/kube-flannel.yml"
  local flannel_mod="$CACHE/kube-flannel.mod.yml"
  msg "download flannel manifest"
  if [[ ! -e $flannel ]]; then
    curl https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml > $flannel
  fi

  # different CNI addon requires different pod-network-cider, here is for flannel
  local cidr=$(perl -ne 'print $1 if /"Network":\s*"([^"]+)"/' $flannel)
  local cidr_svc="10.96.0.0/16"

  local name="$HOST_NAME"
  local ckey="$(kubeadm certs certificate-key)"
  local token="$(kubeadm token generate)"
  local params="--kubernetes-version=$VERSION --apiserver-advertise-address=$ADDRESS --pod-network-cidr=$cidr --token=$token"
  local extras=
  local repo_config=
  local sans_config='  - "localhost"'
  local cpep_config=
  local ckey_config=
  local sock_config=
  local sock_option=

  if [[ -n $SANS ]]; then
    params="$params --apiserver-cert-extra-sans=$SANS"
    for s in $(echo $SANS | tr , '\n')
    do
      sans_config="$(printf '%s\n  - "%s"' "$sans_config" "$s")"
    done
  fi
  if [[ -n $ENDPOINT ]]; then
    # need HA
    params="$params --control-plane-endpoint=$ENDPOINT --certificate-key=$ckey --upload-certs"
    cpep_config="controlPlaneEndpoint: \"$ENDPOINT\""
    ckey_config="certificateKey: \"$ckey\""
    extras="$extras --upload-certs"
    msg "control-plane endpoint specified, upload the certificates for HA setup"
  fi
  if [[ -n $NODE ]]; then
    params="$params --node-name=$NODE"
    name="$NODE"
  fi
  if [[ $NEED_MIRROR == "y" ]]; then
    local repo="registry.aliyuncs.com/google_containers"
    params="$params --image-repository $repo"
    repo_config="imageRepository: \"$repo\""
    msg "mirror is required, use image repository: $repo"
  fi
  if [[ $NEED_CRI_DOCKERD == "y" ]]; then
    sock_option="--cri-socket $CRI_DOCKERD_SOC"
    sock_config="  criSocket: \"$CRI_DOCKERD_SOC\""
    params="$params $sock_option"
    msg "set cri-socket as $CRI_DOCKERD_SOC"
  fi

  # use the same cgroup driver as the container runtime (Docker)
  local cgroupdriver="$($DOCKER info -f {{.CgroupDriver}})"

  cat <<EOF > $INIT_CONFIG
apiVersion: kubeadm.k8s.io/v1beta3
kind: InitConfiguration
bootstrapTokens:
- token: "$token"
  description: "kubeadm bootstrap token"
  ttl: "24h"
localAPIEndpoint:
  advertiseAddress: "$ADDRESS"
nodeRegistration:
  name: "$name"
$sock_config
$ckey_config
---
apiVersion: kubeadm.k8s.io/v1beta3
kind: ClusterConfiguration
kubernetesVersion: $VERSION
$cpep_config
networking:
  serviceSubnet: $cidr_svc
  podSubnet: "$cidr"
apiServer:
  certSANs:
$sans_config
$repo_config
---
apiVersion: kubelet.config.k8s.io/v1beta1
kind: KubeletConfiguration
cgroupDriver: $cgroupdriver
EOF

  # patch proxy env vars
  local no_proxy_more="$K8S_NOPROXY,$cidr,$cidr_svc"
  for e in no_proxy NO_PROXY
  do
    if [[ -n ${!e} ]]; then
      msg "patch $e: $no_proxy_more"
      eval $e="$no_proxy_more,${!e}"
    fi
  done

  if [[ $OFFLINE == "y" && -f $CACHE_IMAGE ]]; then
    msg "try to load cached container images"
    $CACHE_IMAGE load
  fi

  msg "init k8s control-plane node, ver:$VERSION, api:$ADDRESS"
  msg "details in $INIT_CONFIG"
  # TODO: remove $params once the --config way is stable
  # for debug purpose
#  $SUDO env $(env | grep -i proxy) kubeadm init $params
  $SUDO env $(env | grep -i proxy) kubeadm init --config $INIT_CONFIG $extras

  # config
  msg "setup config to access cluster"
  mkdir -p $HOME/.kube
  $SUDO cp /etc/kubernetes/admin.conf $HOME/.kube/config
  $SUDO chown $(id -u):$(id -g) $HOME/.kube/config

  # untaint control-plane
  if [[ $NO_WORKLOAD != "y" ]]; then
    msg "allow to schedule pods on the control-plane"
    kubectl taint nodes --all node-role.kubernetes.io/master-
  fi

  # install flannel to manage the network
  if [[ $BACKEND == 'none' ]]; then
    msg "no flannel is required, you should deploy CNI plugin by yourself"
  else
    msg "deploy flannel: $flannel_mod"
    local cmds=$(cat <<EOF
      if (/^\s+"Backend":\s*\{/ .. /^\s+\}\s*$/) {
        s/^(\s+)("Type":\s*).+$/\$1\$2"$BACKEND",\n\$1"PersistentKeepaliveInterval": 25/
      }
EOF
    )
    perl -pe "$cmds" $flannel > $flannel_mod
    kubectl apply -f $flannel_mod
  fi

  msg "generate instructions to join the cluster"
  msg "details in $JOIN_MANUAL"
  local apiserver="$ADDRESS:$PORT"
  if [[ -n $ENDPOINT ]]; then
    local host port
    IFS=":" read host port <<< "$ENDPOINT"
    if [[ -z $port ]]; then
      port="$PORT"
    fi
    apiserver="$host:$port"
  fi
  local algo="sha256"
  local capath="/etc/kubernetes/pki/ca.crt"
  local cahash="$(openssl x509 -pubkey -in $capath \
	  | openssl rsa -pubin -outform der 2>/dev/null \
	  | openssl dgst -$algo -hex | sed 's/^.* //')"

  cat <<EOF | tee $JOIN_MANUAL
# to join a worker node
sudo kubeadm join $apiserver $sock_option \\
  --token $token \\
  --discovery-token-ca-cert-hash $algo:$cahash

EOF

  if [[ -n $ENDPOINT ]]; then
    cat <<EOF | tee -a $JOIN_MANUAL
# to join a control-plane node
sudo kubeadm join $apiserver $sock_option \\
  --token $token \\
  --discovery-token-ca-cert-hash $algo:$cahash \\
  --control-plane \\
  --certificate-key $ckey

EOF
  fi

}

main "$@"
