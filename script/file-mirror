#!/usr/bin/env bash
# author: joe.zheng
# version: 24.03.20

set -e

SELF="$(basename $0)"
SELF_VERSION="$(sed -n '1,4s/# version: \(.*\)/\1/p' $0)"

DIR_HOME="${DIR_HOME:-$(dirname $0)/files}"
DIR_REPO="$DIR_HOME/repo"
CFG_REPO="$DIR_HOME/repo.conf"
DIR_DOWNLOAD="$DIR_HOME/.download"

SVC_NAME="${SVC_NAME:-file}" # container name
SVC_PORT="${SVC_PORT:-9070}" # port number

DRY_RUN="${DRY_RUN:-n}"
RUN='' # command prefix for dry run
if [[ $DRY_RUN == 'y' ]]; then
  RUN='echo'
fi

PREFIX='> '
DELIMITER='^'

function usage() {
  cat <<EOF
Usage: $SELF [command] [args]
  Download files and serve a local file server

  The downloading files will be saved at a temporary folder ($DIR_DOWNLOAD),
  a hard link will be created in the final folder ($DIR_REPO) if the download
  is successful, otherwise it will exit, and it supports continue download for
  the next run.

  It can support to download file from mutiple sources, try one by one until
  any one is successful. You can append multiple sources in the url separated
  by a delimiter ($DELIMITER)

Commands:
  pull [<url>...]  download the files, read from stdin if no url
  get <url>        download first and get the local file path
  serve            start the local file server

Environment variables:
  DRY_RUN:     print out information only, if it is "y", default: $DRY_RUN
  DIR_HOME:    root folder for this app, default: $DIR_HOME
  SVC_NAME:    container name to use: default: $SVC_NAME
  SVC_PORT:    port number to listen: default: $SVC_PORT

HTTP proxy:

  It can support to be as an HTTP proxy, just request it with a "/proxy" prefix
  for the target url, e.g., assume it listens on "http://host:port", and the
  target url is "https://target/path/file", you can request it as following:

    curl -L http://host:port/proxy/https://target/path/file

  It will try to find file locally first, if not exist, requests remote server
  for the target url and respond to the client just like an HTTP proxy

Examples:

  # Print out how it will be processed
  DRY_RUN=y $SELF pull https://iffi.me/{demo-bot,file-mirror}

  # Download files from remote server
  $SELF pull https://iffi.me/{demo-bot,file-mirror}

  # Get the local file path
  $SELF get https://iffi.me/demo-bot

  # Start the local file server
  $SELF serve

  # Download file from multiple sources
  f=go1.16.linux-amd64.tar.gz && \\
  $SELF pull https://dl.google.com/go/\$f^https://https://golang.google.cn/dl/\$f

  # Download files with a file list
  cat file-list.txt | $SELF pull

  # Get url through $SELF as a HTTP proxy
  target=https://github.com/joez/ptk/raw/master/Changes
  curl -L localhost:$SVC_PORT/proxy/\$target

Version: $SELF_VERSION
EOF
}

function msg {
  echo "$PREFIX$@"
}

function err {
  echo "$PREFIX$@" >&2
}

function has() {
  [[ -z "${1##*$2*}" ]] && [[ -z "$2" || -n "$1" ]]
}

function smart_download() {
  local dir="$DIR_REPO"
  local tmp="$DIR_DOWNLOAD"

  for i in "$@"; do
    msg "download: $i"
    local name="$(basename $i)"
    local downloading="$tmp/$name"
    local downloaded="$dir/$name"

    if [[ -f "$downloaded" ]]; then
      msg "already downloaded"
      msg "OK: $downloaded"
      break
    fi

    if has "$i" $DELIMITER; then
      msg "has multiple sources"
      IFS=$DELIMITER read -a choices <<< "$i"
      for c in "${choices[@]}"; do
        msg "trying: $c"
        if [[ $DRY_RUN != 'y' ]]; then
          if wget -c -t 3 -T 5 -P $tmp $c; then
            ok='y'
            break
          fi
        fi
      done
      if [[ $ok != 'y' && $DRY_RUN != 'y' ]]; then
        err "all failed"
        exit 1
      fi
    else
      $RUN wget -c -P $tmp $i
    fi
    $RUN ln -f $downloading $downloaded
    msg "OK: $downloaded"
  done
}

function create_svc_conf {
  mkdir -p "$(dirname $1)"
  cat <<'EOF' > $1
user  nginx;
worker_processes  auto;

error_log  /var/log/nginx/error.log notice;
pid        /var/run/nginx.pid;

events {
    worker_connections  1024;
}

http {
    include       /etc/nginx/mime.types;
    default_type  application/octet-stream;

    log_format  main  '$remote_addr - $remote_user [$time_local] "$request" '
                      '$status $body_bytes_sent "$http_referer" '
                      '"$http_user_agent" "$http_x_forwarded_for"';
    access_log  /var/log/nginx/access.log  main;

    sendfile           on;
    keepalive_timeout  65;

    limit_conn_zone $binary_remote_addr zone=addr:10m;
    limit_req_zone  $binary_remote_addr zone=one:10m rate=1r/s;

    server {
        listen       8080;
        server_name  localhost;
        root         /repo;

        # default security control, very restricted!
        limit_conn addr 2;
        limit_req  zone=one;
        limit_rate 10k;

        # to make it easy for /proxy/http://host/*
        # otherwise the http:// will become http:/
        merge_slashes off;

        # dns resolution for proxy
        resolver 8.8.8.8;
        # disable proxy buffering for simplicity
        proxy_buffering off;

        location / {
            autoindex on;
            autoindex_exact_size off;
            autoindex_localtime on;
            charset utf-8;
        }

        location ~ ^/proxy/?$ {
            return 200 OK;
        }

        # try local file first, and then the original server
        # e.g. /proxy/http://target/path
        # try /path first, then request http://target/path
        location ~ ^/proxy/https? {
            rewrite ^/proxy/(.+(/[^/]+))$ $1 break;
            try_files $2 @proxy;
        }
        location @proxy {
            proxy_pass $uri;

            # follow redirects
            proxy_intercept_errors on;
            error_page 301 302 307 = @proxy_redirect;
        }
        location @proxy_redirect {
            set $saved_redirect_location $upstream_http_location;
            proxy_pass $saved_redirect_location;
        }
    }
}
EOF

}

if [[ -z "$1" || "$1" == "-h" || "$1" == "--help" || "$1" == "help" ]]; then
  usage && exit
else
  cmd="$1"
  shift
fi

$RUN mkdir -p $DIR_HOME $DIR_REPO

if [[ "$cmd" == "pull" ]]; then
  if [[ -t 0 ]]; then
    # pass args into stdin
    exec < <(printf '%s\n' "$@")
  fi
  while IFS= read -r url; do
    msg "processing $url"
    smart_download "$url"
  done
elif [[ "$cmd" == "get" ]]; then
  [[ -z "$1" ]] && exit 1
  smart_download "$1" >&2
  downloaded="$DIR_REPO/$(basename $1)"
  [[ -f "$downloaded" ]] && echo "$downloaded"
  exit
elif [[ "$cmd" == "serve" ]]; then
  SUDO=""
  if [[ $(id -u) != "0" ]]; then
    SUDO="sudo"
  fi

  if [[ ! -f $CFG_REPO ]]; then
     msg "create $CFG_REPO"
     $RUN create_svc_conf $CFG_REPO
  fi
  if $SUDO docker container inspect -f '{{.ID}}' $SVC_NAME >/dev/null; then
    msg "stop and delete the old container: $SVC_NAME"
    $RUN $SUDO docker rm -f $SVC_NAME
  fi
  msg "create container: $SVC_NAME"
  $RUN $SUDO docker create --name $SVC_NAME \
    -v $(realpath $DIR_REPO):/repo \
    -v $(realpath $CFG_REPO):/etc/nginx/nginx.conf \
    -p $SVC_PORT:8080 --restart unless-stopped \
    nginx:1.23.4-alpine
  msg "start container: $SVC_NAME"
  $RUN $SUDO docker start $SVC_NAME

  cat <<EOF
# check the local repo
  no_proxy='*' curl localhost:$SVC_PORT
EOF
else
  err "not supported cmd: $cmd"
  exit 1
fi

msg "done"
